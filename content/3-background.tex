\chapter{АНАЛИЗ ПРЕДМЕТНОЙ ОБЛАСТИ}
\label{ch:АНАЛИЗ ПРЕДМЕТНОЙ ОБЛАСТИ}

В этой главе представлен анализ современного состояния предметной области и обзор существующих подходов, обсуждаются преимущества и недостатки существующих подходов. Каждый раздел завершается краткой резюмирующей секцией, в которой указывается выбранный подход и приводится короткая аргументация.

\section{Методы обнаружения аномалий}

Согласно \cite{article:15_survey_ad}, задача обнаружения аномальных событий и поведений, которая является основный фокусом этой работы, была предметом интереса и исследований научного сообщества начиная с XIX вв. В настоящее время существует огромное разнообразие различных методов для решения задачи обнаружения аномалий и отклонений, применимых к данным видеотрафика, и эти подходы могут быть классифицированы различными способами.

Например, методы интеллектуального анализа данных в целом и методы обнаружения аномалий, а также алгоритмы кластеризации, которые в частности являются одним из способов решения задачи идентификации аномалий, могут быть классифицированы как контролируемые, полууправляемые и неконтролируемые на основании способа маркировки входных данных \cite{article:15_survey_ad} \cite{article:comp_analys_odt}:

\begin{enumerate}
	\setlength\itemsep{-0.5em}
	\item \textit{Контролируемые, Supervised}. Входные данные, используемые для обучения модели, содержат метки как для нормальных, так и для аномальных экземпляров данных. В результате алгоритм может строить модели как для нормальных, так и для аномальных классов;

	\item \textit{Полууправляемые, Semi-Supervised \cite{article:15_survey_ad}} or \textit{Weakly-Supervised \cite{article:5_survey_tbsa}}. Входной набор обучающих данных содержит метки классов только для нормальных экземпляров данных. Такие методы находят более широкое применение, нежели контролируемые подходы, поскольку аномальные экземпляры данных, как правило, непредсказуемы и случайны, и трудно заранее привести примеры, охватывающие всевозможные аномальные события;

	\item \textit{Неконтролируемые, Unsupervised}. Не требуют, чтобы входные данные были помечены ни для нормальных, ни для аномальных данных. Такие алгоритмы основаны на предположении, что нормальные экземпляры данных встречаются в наборе тестовых данных значительно чаще, нежели аномальные. И, следовательно, данные методы неприменимы в случаях, когда это предположение нарушается.

\end{enumerate}

С другой стороны, согласно опросам, проведенным Чандолой в \cite{article:15_survey_ad}, Кумараном в \cite{article:6_survey_anom_det_rtuvs} и Маликом в \cite{article:comp_analys_odt}, методы обнаружения аномалий могут классифицироваться на основании базовой используемой методики, например: методы, основанные на классификации, на методе ближайших соседей, на кластеризации, статистике и т.д. Ниже приводится краткий обзор каждой из упомянутых групп.

\subsubsection{Основанные на кластеризации}

Основная концепция этих методов заключается в использовании классификатора, который сначала учится различать неискаженные и искаженные значения, а затем классифицирует каждый входной экземпляр \cite{inproceedings:18_ardod_lstd}. Такие методы состоят из этапов обучения и тестирования. Фаза обучения предполагает изучение модели классификатора из набора обучающих данных, содержащего помеченные экземпляры данных. Изученный классификатор затем используется для классификации входной траектории как нормальной или аномальной путем присвоения метки класса на этапе тестирования.

В зависимости от того, как маркируются экземпляры данных тестирования, все методы обнаружения аномалий на основе классификации могут быть одноклассовыми или многоклассовыми. Первый тип предполагает, что все экземпляры обучающих данных являются нормальными и помечены как один класс. Во время фазы обучения модель изучает дискриминационную границу вокруг нормальных экземпляров, и траектория, которая не соответствует описанию изученного нормального класса, считается аномальной. Одноклассовые Support Vector Machines (SVMs) - это наиболее часто используемый подход, основанный на классификации, который применим к задаче обнаружения аномальной траектории, как это было предложено Piciarelli \textit{et al.} \cite{inproceedings:16_va_tad_svm} \cite{article:17_tbaed}. Однако этот подход требует, чтобы векторы траектории были одинаковой длины. Поскольку необработанные данные о траекториях обычно содержат различное количество точек траектории из-за разной скорости движущихся объектов, необходимо предварительно обработать необработанные траектории, чтобы нормализовать их и привести к векторам одинаковой длины \cite{article:17_tbaed}. Более того, SVM занимают много времени и памяти при работе с огромными объемами многомерных данных \cite{article:22_survey_dscc}.

Вторая категория предполагает изучение нескольких классов на этапе обучения, а затем использование классификатора для проверки входной траектории на соответствие каждому изученному классу. В литературе приводятся различные описания фазы обучения и меток данных обучения. Согласно \cite{article:15_survey_ad}, данные обучения содержат только нормальные экземпляры данных с соответствующими метками нормальных классов, а во время фазы обучения модель изучает множество дискриминационных границ вокруг каждого класса нормальных экземпляров. Траектория, которая не соответствует ни одному из изученных нормальных описаний классов, считается аномальной. Другими словами, аномальная траектория не будет принята ни одним из классификаторов. В \cite{article:6_survey_anom_det_rtuvs} предполагается, что модель изучается с использованием обучающих данных, содержащих метки для нормальных и аномальных классов. Следовательно, классификатор может классифицировать входную траекторию как принадлежащую нормальному или аномальному классу.

Преимущество двухэтапных алгоритмов, основанных на классификации, заключается в быстрой фазе тестирования благодаря предварительно рассчитанной модели классификатора, используемой для классификации каждого входного экземпляра. Также такие алгоритмы могут хорошо работать в случаях, когда аномальные экземпляры данных образуют класс или кластер \cite{inproceedings:18_ardod_lstd}. Однако для этапа обучения требуются четко помеченные данные обучения, которые часто недоступны.

\subsubsection{Основанные на методе ближайших соседей \cite{article:15_survey_ad} или Основанные на близости / плотности распределения \cite{article:6_survey_anom_det_rtuvs}\cite{inproceedings:18_ardod_lstd}}

Подходы на основе близости определяют, является ли экземпляр данных нормальным или аномальным, основываясь на том, насколько близко или далеко он расположен по отношению к соседям \cite{article:6_survey_anom_det_rtuvs}. Подходы, основанные на ближайших соседях и плотности, базируются на предположении, что «нормальные экземпляры данных имеют плотную окрестность, в то время как аномальные экземпляры данных встречаются далеко от их ближайших соседей» \cite{article:15_survey_ad}.

Чтобы иметь возможность сравнивать окружающую плотность для рассматриваемого экземпляра с плотностью вокруг его локальных соседей, необходимо указать меру расстояния (различия) или сходства между двумя экземплярами данных \cite{inproceedings:18_ardod_lstd}. С помощью метода вычисления оценки аномалии методы могут быть сгруппированы в две категории: 1) оценка аномалии рассчитывается как расстояние экземпляра данных до его $k$-го ближайшего соседа и 2) для вычисления относительной оценки аномалии вычисляется плотность каждого экземпляра данных \cite{article:15_survey_ad}.

У данных подходов есть несколько недостатков. Прежде всего, по сравнению с методами обнаружения аномалий, основанных на классификации, вычислительная сложность этапа тестирования значительно выше, поскольку ближайшие соседи вычисляются путем вычисления расстояния для каждого экземпляра тестовых данных со всеми экземплярами из данных тестирования или обучения. В случае многомерных данных траекторий задача вычисления расстояния становится еще более сложной. Кроме того, точность маркировки уменьшается, когда основное предположение нарушается: когда нормальные экземпляры имеют разреженную окрестность или аномальные экземпляры имеют плотную \cite{article:15_survey_ad}.

\subsubsection{Основанные на кластеризации}

Кластеризация - это эффективный подход, направленный на группирование экземпляров данных в разные классы, называемые кластерами, на основе их сходства таким образом, что объекты в одном кластере похожи друг на друга и не похожи на объекты в других кластерах \cite{article:8_review_mot_cl_alg}\cite{article:22_survey_dscc}. Кластеризация пространственно-временных данных предполагает группирование объектов на основании их пространственного и временного сходства. Чтобы сравнить экземпляры данных перед их объединением в кластеры, необходимо измерить сходство или расстояние между ними.

Существует три типа методов обнаружения аномалий на основе кластеризации со следующими допущениями: 1) нормальные экземпляры данных относятся к кластеру, в то время как аномальные экземпляры данных не связаны ни с одним кластером, 2) нормальные экземпляры данных находятся близко к центру кластера, а аномальные экземпляры лежат далеко от ближайшего центра кластера, и 3) нормальные экземпляры данных лежат в больших и плотных кластерах, тогда как аномалии связаны с разреженными кластерами или кластерами с небольшим числом элементов \cite{article:15_survey_ad}\cite{article:6_survey_anom_det_rtuvs}. Методы первого типа могут быть реализованы с использованием одного из методов кластеризации, которые не требуют, чтобы каждый экземпляр данных принадлежал к какому-либо кластеру, например, DBSCAN \cite{inproceedings:20_dbscan}. Алгоритмы из второй группы состоят из двух этапов: 1) кластеризация данных и 2) вычисление оценки аномалий для каждого экземпляра данных. Методы последнего типа требуют порогового значения для размера кардинальности и/или плотности кластера, который должен быть определен, чтобы решить, относится ли кластер к нормальным или аномальным данным.

Необходимость вычисления расстояния между траекториями в некоторых подходах на основе кластеризации делает их похожими на подходы, основанные на методе ближайших соседей. Как указано в \cite{article:15_survey_ad}, основное различие этих методов заключается в том, как они обрабатывают экземпляры данных: в методах на основе кластеризации каждый экземпляр оценивается относительно соответствующего кластера, в то время как в методах на основе ближайших соседей каждый экземпляр проверяется в отношении к ближайшим соседям и рассматривается вместе со своим ближайшим соседством. Следовательно, выбор метода вычисления расстояния играет важную роль и существенно влияет на результаты и производительность.

С другой стороны, разделение всех обучающих данных на группы делает алгоритмы на основе кластеризации похожими на алгоритмы на основе классификации. Хотя в подходах на основе классификации класс назначается на основе заданных меток, в то время как в подходах на основе кластеризации классификация заранее не указывается \cite{inproceedings:18_ardod_lstd}.

Одним из основных преимуществ методов, основанных на кластеризации, является способность большинства из них работать без присмотра, в неконтролируемом режиме. В случае получения данных о траекториях с видеокамер наблюдения, наиболее подходящими являются методы обучения без контроля, поскольку классификация и маркировка часов видеоданных является весьма трудоемкой задачей. Кроме того, ручная маркировка входных данных может привести к ошибкам из-за вмешательства оператора, как результат введение человеческого фактора.

Более того, методы на основе кластеризации могут приспосабливаться к работе со сложными типами данных благоаря адаптируемости алгоритмов кластеризации. Однако в то же время они являются дорогостоящими в вычислительном отношении и используются в основном для сравнительно низкоразмерных данных, сильно зависимы от выбранного алгоритма кластеризации и не могут эффективно справляться с ситуациями, когда аномалии формируют значительные отдельные кластерные группы \cite{article:15_survey_ad}.

\subsubsection{Методы с применением моделей  \cite{article:6_survey_anom_det_rtuvs}\cite{inproceedings:18_ardod_lstd} или Статистические \cite{article:15_survey_ad}}

Основная концепция алгоритмов, основанных на использовании моделей, заключается в том, что они представляют данные в виде набора параметров для создания модели нормального поведения. Одним из преимуществ таких подходов, основанных на использовании модели, является то, что они не требуют от пользователя ввода каких-либо входных параметров, поскольку все значения параметров могут быть получены из данных. Подходы, основанные на статистике, можно рассматривать как подкатегорию подходов, основанных на использовании моделей, и они считаются одними из самых ранних алгоритмов и могут использоваться в качестве основы различными методами обнаружения аномалий \cite{article:comp_analys_odt}. Как указано в \cite{article:15_survey_ad}, основная идея статистических подходов состоит в том, что экземпляры данных, возникающие в областях высокой вероятности стохастической модели, считаются нормальными, тогда как экземпляры данных из областей низкой вероятности относятся к аномалиям. Таким образом, статистические подходы основаны на использовании статистической стохастической модели для подгонки к заданным данным и последующем применении статистического теста вывода, также называемого тестом на несоответствие, чтобы определить, является ли экземпляр данных нормальным или аномальным. Из основной концепции следует, что «на основе результатов прикладного статистического теста аномалии имеют низкую вероятность быть сгенерированными из изученной стохастической модели» \cite{article:15_survey_ad}.

Статистические методы в свою очередь могут быть параметрическими или непараметрическими \cite{article:comp_analys_odt}. В параметрических подходах нормальные данные должны соответствовать параметрическому распределению и функции плотности вероятности с параметрами, вычисленными на основании заданных данных \cite{article:6_survey_anom_det_rtuvs}. Одним из преимуществ параметрических методов является то, что размер данных не влияет на модель: модели растут только в зависимости от сложности модели. Однако необходимость приспособить данные под какую-то заранее выбранную модель распределения усложняет и ограничивает применение таких подходов: сложности возникают при сопоставление данных одному распределению. В этом случае можно использовать модель множественного распределения, чтобы сопоставить некоторые кластеры данных с конкретными распределениями \cite{inproceedings:18_ardod_lstd}. Одним из наиболее известных примеров параметрических методов является метод регрессии \cite{article:comp_analys_odt}.

В противоположность этому, непараметрические подходы основаны на использовании непараметрических статистических моделей со структурами, которые не определены заранее: исходные данные используются для динамического определения структуры. Такие подходы не основываются на заранее сделанных предположениях о статистическом распределении данных \cite{article:comp_analys_odt}.

Поскольку статистические подходы основаны на подборе статистической модели, ee выбор существенно влияет на результаты, сложность вычислений и производительность. Тем не менее, основное допущение статистических подходов, которое заключается в том, что данные поступают из определенного распределения, не всегда может быть выполнено, особенно для случая многомерных данных \cite{article:15_survey_ad}.

\subsubsection{Выводы}

На основании приведенного описания различных подходов, их преимуществ и недостатков, было решено сосредоточиться на подходах обнаружения аномалий на основе кластеризации по нескольким причинам:

\begin{enumerate}[label=\arabic*)]
	\setlength\itemsep{-0.5em}
	\item они могут работать в режиме без контроля без вмешательства оператора и человеческого фактора и не требуют наличия меток во входных данных,
	\item входные данные могут содержать экземпляры аномальный таректорий,
	\item метод кластеризации может быть легко применен к таким многомерным данным, как траектории, путем определения подходящей меры подобия.
\end{enumerate}

Из этого следует, что необходимо определиться с методом кластеризации и метрикой измерения сходства траекторий.

\section{Классификация методов кластеризации}

Кластеризация является одной из наиболее глубоко изученных форм интеллектуального анализа данных, и огромное разнообразие методов кластеризации уже было предложено и реализовано \cite{article:8_review_mot_cl_alg}. Анализ современного состояния  предметной области и связанных исследовательских работ показал, что все традиционные подходы кластеризации обычно делятся на пять типов: методы разделения (декомпозиции), иерархические, основанные на плотности, основанные на моделях и методы на основе сетки \cite{article:5_survey_tbsa}\cite{article:8_review_mot_cl_alg}. В следующих параграфах будет кратко представлена концепция каждой из категорий с выделением основных предположений и обсуждением преимуществ и недостатков.

\subsubsection{Методы, основанные на разделении или декомпозиции}

Эта категория методов объединяет методы, основанные на случайном разделении данных траекторий, а затем перегруппировке кластеров путем переназначения объектов из одного кластера в другой для минимизации целевой функции. Методы требуют предварительного определения значения параметра, обычно обозначаемого как $k$, который определяет количество конечных кластеров, которые должны быть сформированы на базе исходных данных. Основное требование заключается в том, что количество итоговых разделов должно быть меньше числа исходных точек данных, поскольку каждый раздел образует кластер. Это означает, что каждый раздел должен быть непустым и содержать как минимум один экземпляр данных, а каждый экземпляр данных должен быть включен в ровно один кластер.

Одним из наиболее известных алгоритмов кластеризации, основанных на разделении, является алгоритм $K$-Means, в котором сначала $k$ кластерных центров инициализируются случайным образом, а затем точки данных итеративно переназначаются в ближайший центр кластера на основе отличия, несоответсвтия, чтобы минимизировать итоговую ошибку кластеризации \cite{article:23_survey_ca}. Ошибка кластеризации определяется как сумма квадратов Евклидовых расстояний между каждой точкой набора данных и соответствующим центром кластера \cite{article:24_glkkm_cl_fs}. Процесс прекращается, когда в кластерных центрах больше нет изменений.

Недостатками традиционного метода кластеризации K-Means являются невозможность формирования кластеров произвольной формы, сильная зависимость от начальной случайной инициализации центров кластеров и высокое потребление памяти \cite{article:8_review_mot_cl_alg}. Также сложной задачей является поиск подходящей техники разбиения.

\subsubsection{Иерархические методы}

В иерархических методах исходный набор данных разбивается на несколько уровней для организации в виде иерархического дерева кластеров. Полученная иерархическая структура может быть изображена в виде дерева \cite{article:23_survey_ca}.

Существует два различных способа иерархической декомпозиции: 1) восходящая (комбинирующая) и 2) разделяющая (декомпозиционная). Они называются агломеративной дивизивной (дивизионной) кластеризациями соответственно \cite{online:what_is_hier_clust}.

Агломеративные алгоритмы иерархической кластеризации начинаются с присвоения каждого экземпляра данных отдельному одноэлементному кластеру, при этом число начальных кластеров равняется точному количеству экземпляров данных во входных данных, а затем продолжается процесс объединения кластеров на основе их сходства, пока все начальные кластеры не будут объединены в один кластер или в заранее определенное количество кластеров \cite{online:unders_hier_cl}. Это делается путем многократного выполнения следующих двух шагов: 1) определение двух ближайших кластеров и затем 2) объединение этих двух кластеров \cite{online:what_is_hier_clust}. Матрица близости кластеров используется для хранения значений схожести между кластерами и обновляется на каждом этапе путем вычисления расстояний между новым кластером и другими кластерами.

Дивизивные алгоритмы иерархической кластеризации работают в обратном порядке: сначала все экземпляры данных принадлежат одному кластеру, а затем шаг за шагом кластеры разбиваются на более мелкие кластеры, пока все кластеры не станут одноэлементными кластерами или пока не будут удовлетворены некоторые предварительно определенные конечные условия.

Предполагается, что иерархическая кластеризация является простым алгоритмом, однако возникает необходимость выбора между агломеративными и дивизивными методами. Дивизивная кластеризация более затратна в вычислениях, поэтому она менее распространена, нежели аглометивные подходы. Необратимость процессов расщепления или объединения кластеров в традиционных алгоритмах иерархической кластеризации также является особенностью и сложностью таких алгоритмов \cite{article:8_review_mot_cl_alg}.

Поскольку агломеративный подход включает объединение кластеров, важной задачей алгоритмов агломеративной кластеризации является определение и вычисление сходства или расстояния между кластерами. Это сходство может также называться межкластерным расстоянием. В случае двух кластеров с одной траекторией в каждой из них сходство между ними упрощено и равно значению схожести между соответствующими траекториями. Для кластеров с несколькими траекториями сходство вычисляется в соответствии с выбранным методом связи. В литературе в качестве наиболее распространенных приводятся следующие методы связи: средняя ссылка (метод связи по одной минимальной ссылке, single linkage), максимальная ссылка (метод связи по максимальной ссылке, maximum linkage), средняя ссылка (метод связи по усредненной ссылке, average linkage) \cite{article:23_survey_ca}\cite{inproceedings:7_related_work}. Выбор метода связывания зависит от домена приложения \cite{online:what_is_hier_clust}. В single linkage расстояние между двумя кластерами определяется как минимальное расстояние между двумя траекториями из этих кластеров, что означает, что сходство между двумя кластерами определяется двумя ближайшими траекториями. Метод average linkage связывания подразумевает выбор максимального расстояния между двумя траекториями в двух кластерах в качестве межкластерного расстояния, то есть оно определяется с использованием самого дальнего расстояния между парами траекторий. Метод average linkage предполагает вычисление усредненного расстояния между всеми парами траекторий в рассматриваемых двух кластерах.

Удобство подходов агломеративной иерархической кластеризации заключается в том, что они не требуют предварительно заданного числа итоговых кластеров, поэтому они подходят для кластеризации траекторий ТС, поскольку количество кластеров с нормальными или аномальными траекториями заранее неизвестно. Однако наиболее известным недостатком алгоритмов иерархической кластеризации является то, что они не устойчивы к шуму и могут страдать от аномалий.

\subsubsection{Плотностные алгоритмы}

По сравнению с подходами основанной на разделении или иерархической кластеризации методы, основанные на плотности, определяют сходство на основе их плотности \cite{article:22_survey_dscc}. Область с данными добавляется к ближайшему кластеру, если плотность точек в области остается больше, чем предопределенное пороговое значение \cite{article:8_review_mot_cl_alg}. Кластеры образуют плотные области объектов и разделены разреженными областями с низкой плотностью.

Основное преимущество подходов кластеризации на основе плотности заключается в том, что они способны формировать кластеры произвольной формы, а не только сферической \cite{article:8_review_mot_cl_alg}. Также они подходят для бесконтрольной кластеризации огромных наборов данных траекторий и не требуют заранее заданного количества кластеров \cite{article:5_survey_tbsa}\cite{article:22_survey_dscc}. Однако качество результатов сильно зависит от количества траекторий в наборе обучающих данных, доступных для анализа: при малом размере обучающего набора данных результаты будут недостоверными и неточными.

Наиболее известным и широко используемым алгоритмом на основе плотности является DBSCAN, предложенный автором М. Эстер в \cite{inproceedings:20_dbscan}. В соответствии с этим алгоритмом точки входных данных могут быть классифицированы следующим образом: ядровые центральные точки (корневые или ядерные объекты, ключевые точки), плотно-достижимые объекты и аномалии на основе параметров $\varepsilon$, \textit{minPts} и пороговое значение плотности. Параметр $\varepsilon$ и \textit{minPts} задают максимальную удаленность (максимальную окрестность точки) и минимальное количество удовлетворяющих точек при выборе ключевых точек: как минимум \textit{minPts} точек должны быть расположены внутри $\varepsilon$-окрестности от базовой точки; эти точки называются плотно-достижимыми из выбранной базовой точки. Вышеупомянутые параметры должны быть предварительно определены пользователем, но их трудно определить корректно. Каждый кластер должен содержать хотя бы одну базовую точку. Точки обозначаются как аномальные, если они не являются плотно-достижимыми ни от одной из других точек.

\subsubsection{Алгоритмы на основе использования сеточной структуры данных}

Основная идея алгоритмов кластеризации на основе использования сеточной структуры данных заключается в применении сеточной структуры данных с несколькими разрешениями: пространство данных квантуется на конечное число ячеек (единиц), которые образуют многоразмерную структуру сетки. Каждая ячейка хранит общую информацию об объектах данных в своем подпространстве \cite{article:22_survey_dscc}. Поскольку операции кластеризации выполняются на созданной сетке, а также в каждой ячейке пространственной сетки могут быть вычислены важные характеристики траекторий, качество сжатия данных существенно влияет на качество результатов \cite{article:1_survey_stdm}. Плотность близко расположенных плотных клеток может помочь определить кластеры. Траектория может рассматриваться как аномальная, если она отличается от ожидаемой траектории количеством покрытых ячеек сетки \cite{article:22_survey_dscc}.

Главным преимуществом таких алгоритмов кластеризации на основе сеточной структуры данных является улучшенная производительность: высокая скорость обработки и время обработки становятся независимыми от размера исходных данных, на время обработки влияет только количество ячеек в каждом измерении \cite{article:8_review_mot_cl_alg}.

\subsubsection{Подходы на основе использования моделей}

По сравнению с вышеупомянутыми методами, которые анализируют расстояние между объектами данных, в модельных подходах предполагается, что данные генерируются несколькими распределениями вероятностей, где каждый компонент представляет собой кластер данных. Таким образом, математическая модель присваивается каждому кластеру, а затем метод пытается подобрать наиболее подходящие данные для выбранной модели. Методы этого типа стремятся повысить адаптивность между данными и некоторыми статистическими моделями \cite{article:8_review_mot_cl_alg}\cite{article:22_survey_dscc}. Идея алгоритмов, основанных на использовании моделей, состоит в том, что для определения местоположения кластеров они описывают пространственное распределение точек входных данных с помощью определения функций плотности. Такие подходы обычно используются для кластеризации специфических данных и сильно зависят от выбранных функций и модели \cite{article:5_survey_tbsa}.

Подчеркивается, что подходы, основанные на использовании моделей, показывают хорошую производительность при работе со сложными типами данных. В эту категорию обычно входят статистические и нейронные методы \cite{article:8_review_mot_cl_alg}.

\subsubsection{Графовые алгоритмы \cite{article:1_survey_stdm}}

Графовые алгоритмы представляют собой еще одну категорию методов кластеризации в применении к данным траекторий ТС. Liu в \cite{inproceedings:26_dstci_tds} представил основанный на графах подход для решения проблемы обнаружения аномалий в потоках данных транспортного трафика. Структура графика использовалась для хранения трафика: узлы представляют собой регионы, а граничные веса отображают поток трафика. Краевые аномалии на графике обозначают аномалии движения, и дерево причинных аномалий затем можно использовать для дальнейшего анализа этих аномалий для поиска причинных взаимодействий.

\bigbreak

Другая высокоуровневая классификация методов кластеризации может состоять только из двух подклассов на основе свойств сгенерированных кластеров: иерархические подходы и подходы, основанные на разделении \cite{article:23_survey_ca}. Иерархические алгоритмы группируют объекты в кластеры начиная с одноэлементных кластеров и доходя до одного итогового кластера, содержащего все экземпляры данных, или в обратном направлении. Второй подкласс алгоритмов кластеризации разделяют заданный набор данных на заранее определенное количество кластеров в одноуровневой структуре.

Для выполнения кластеризации необходимо определить метрику сходства между двумя траекториями. Различные существующие меры расстояния будут рассмотрены в следующих секциях.

\subsubsection{Выводы}

На основе приведенного описания различных подходов кластеризации, их ограничений, преимуществ и недостатков, было решено сосредоточиться на алгоритме иерархической кластеризации, а именно на агломеративной иерархической кластеризации, поскольку она может справиться с ограничениями используемых в этой работе входных данных, которые заключаются в следующем: отсутствие входных меток, неизвестное количество результирующих кластеров, присутствие как нормальных, так и аномальных траекторий во входных данных.

\section{Метрики измерения близости и дальности}

Как упоминалось ранее, подходы, основанные на кластеризации, требуют определения меры сходства между двумя траекториями. Кроме того, меры расстояния и подобия также используются для сравнения траектории с кластером или сравнения пары кластеров между собой. Выбор метрики сходства сильно зависит от формата траектории. Траектории, представленные в виде многомерных данных, могут содержать количественные или качественные характеристики, непрерывные или двоичные. В такой классификации функции измерения расстояния больше подходят для работы с непрерывными объектами, а меры сходства - для работы с качественно определенными траекториями \cite{article:23_survey_ca}. Входные траектории-векторы в этой работе содержат пространственную информацию наряду с временной, которую можно назвать качественными непрерывными данными. Это означает, что в этом случае функции измерения расстояния между траекториями являются более подходящими. 

Помимо этого, функции расстояния и подобия могут быть классифицированы как 1) способные принимать необработанные представления траекторий без каких-либо шагов предварительной обработки и 2) ожидающие на вход предварительно обработанные представления траекторий. Предварительная обработка может включать унификацию длины траекторий или уменьшение размерности векторов траекторий \cite{inproceedings:7_related_work}.

Одними из наиболее известных и широко используемых традиционных метрик подобия являются: Евклидово расстояние, расстояние Фреше, DTW, LCSS.

\subsubsection{Евклидово расстояние (Euclidean Distance)}

Евклидово расстояние между двумя векторами траекторий вычисляется как сумма квадратов разностей соответствующих пространственных координат \cite{article:27_vna_cad_td}:

\begin{equation}
	 d_{ij} = ||T_i - T_j||_E = \sqrt{\sum_{k=1}^{m}((t_{i_x}^k - t_{i_x}^k)^2 + (t_{i_y}^k - t_{j_y}^k)^2)}
\end{equation}

где обе траектории состоят из \textit{m} точек слежения и представлены двумерными векторами $T_i = \{t_i^1, t_i^2, \ldots, t_i^m\}$ и $T_j = \{t_j^1, t_j^2, \ldots, t_j^m\}$. Кортежи $(t_{i_x}^k, t_{i_y}^k)$ представляют собой пространственные координаты для \textit{k}-ой точки слежения \textit{i}-ой траектории из набора данных.

Однако Евклидово расстояние работает только с траекториями с равным количеством точек отслеживания. Поскольку обычно ТС движутся с разной скоростью и по разному маршруту, длина траектории всегда различна. Это означает, что исходные траектории необходимо предварительно обработать и привести к единому размеру \cite{inproceedings:7_related_work}. Кроме того, традиционное Евклидово расстояние работает с двумерными данными и не может обрабатывать временную информацию. Более того, Евклидово расстояние зависит от направления траектории: изменение направления на обратное может привести к неправильному измерению расстояния, что, в свою очередь, может привести к ошибкам в кластеризации. Также возможны ошибки при работе с траекториями, движущимися аналогичным образом, но с различными скоростями и частотой дискретизации (частотой измерения) \cite{inproceedings:28_lcss_dsmt}.

\subsubsection{Расстояние Фреше (Fréchet Distance)}

В основе расстояния Фреше лежит Евклидово расстояние. Оно учитывает позиционные и последовательные отношения точек траектории при расчете схожести траекторий. Основная идея этого подхода состоит в том, чтобы вычислить Евклидово расстояние для каждой пары точек из двух траекторий, а затем обозначить максимальное Евклидово расстояние как расстояние Фреше между ними \cite{article:8_review_mot_cl_alg}\cite{inproceedings:29_fr_dist}. Однако, поскольку учитывается только максимальное расстояние, подход чувствителен к наличию аномалий.

\subsubsection{Алгоритм динамической трансформации шкалы времени (DTW)}

Алгоритм динамической трансформации шкалы времени (Dynamic Time Warping, DTW) является одним из алгоритмов измерения сходства между двумя последовательностями временных рядов, которые могут различаться по скорости. Целью методов сравнения временных рядов является создание метрики расстояния между ними. Метод DTW направлен на поиск соответствия между зависимыми от времени последовательностями, такими как траектории, и способен обрабатывать траектории различной длины \cite{article:8_review_mot_cl_alg}.

Согласно \cite{article:8_review_mot_cl_alg}, DTW расстояние может быть вычислено следующим образом (\ref{eq:dtw}):

\begin{equation} \label{eq:dtw}
	D_D(T_i, T_j) = 
		\begin{cases}
			0 				&\text{$m = n = 0$}\\
			\infty 			&\text{$m = 0$ or $n = 0$}\\
			dist(a_i^k, b_j^k) + min 
				\begin{cases}
					D_D(Rest(T_i), Rest(T_j))\\
					D_D(Rest(T_i), T_j)\\
					D_D(T_i, Rest(T_j))
				\end{cases} &\text{others}
		\end{cases}
\end{equation}

где $D_D(T_i, T_j)$ - расстояние DTW между двумя сегментами траектории с длинами $m$ и $n$, $dist(a_i, b_j)$ - Евклидово расстояние между двумя точками траектории. Функция $Rest(T_i)$ берет оставшуюся часть траектории после исключения последней точки траектории $a_i$. Из формулы видно, что в случае траекторий нулевой длины расстояние DTW равно 0, для случая, когда только одна из двух траекторий не пуста, расстояние между ними считается бесконечным. Для двух непустых траекторий минимальное расстояние между ними вычисляется рекурсивным способом.

Хотя важным преимуществом метода DTW является его способность обрабатывать векторы траектории различной длины, расстояние DTW не устойчиво к шуму и требует, чтобы точки траектории были непрерывными. Кроме того, вычисление расстояния DTW является очень трудоемким и сложным из-за необходимости сравнивать расстояния между каждой парой траекторий.

\subsubsection{Метод наибольшей общей подпоследовательности (LCSS)}

Расстояние Longest Common SubSequence (LCSS) пытается сравнивать две последовательности траекторий на основе самой длинной общей подпоследовательности между ними. Алгоритм LCSS работает с дискретными значениями и рассчитывает наибольшее количество эквивалентных точек между двумя траекториями. Задача поиска самой длинной общей подпоследовательности обычно решается рекурсивно \cite{article:8_review_mot_cl_alg}: возможные смещения или сдвиги рассчитываются в каждом измерении и используются для обеспечения максимальной LCSS \cite{online:r_lcss}. Основная идея расстояния LCSS заключается в том, что оно позволяет растягивать две траектории. По сравнению с DTW и Евклидовыми расстояниями, LCSS позволяет некоторым элементам (точкам траектории) оставаться несогласованными \cite{article:tr_sim_meas}, и, по сравнению с DTW, LCSS более устойчив к наличию аномалий \cite{article:ind_mult_ts}.

LCSS метрика может быть рассчитана по следующей формуле (\ref{eq:dlcss}) \cite{inproceedings:7_related_work}:

\begin{equation} \label{eq:dlcss}
	D_{LCSS}(T_1, T_2) = 1 - \frac {LCSS_{\delta, \epsilon}(T_1, T_2)} {min(m, n)}
\end{equation}

где $m$ и $n$ - длины траекторий $T_1$ и $T_2$ соответственно. $\frac{LCSS_{\delta, \epsilon}(T_1, T_2)}{min(m, n)}$ также может называться метрикой схожести LCSS и принимает значение от 0 до 1.

$LCSS_{\delta, \epsilon}(T_1, T_2)$, самая длинная общая подпоследовательность между траекториями, представляет собой количество совпадающих точек траектории между траекториями $T_1$ и $T_2$ и определяется следующим образом (\ref{eq:lcss}):

\begin{equation} \label{eq:lcss}
	LCSS_{\delta, \epsilon}(T_1, T_2) = 
		\begin{cases}
			0 			&\text{if $m = 0$ or $n = 0$}\\
						&\text{(if $|t_{1_{x,m}} - t_{2_{x,n}}| \textless \epsilon$}\\
			1 + LCSS_{\delta, \epsilon}(Head(T_1), Head(T_2)) 
						&\text{and $|t_{1_{y,m}} - t_{2_{y,n}}| \textless \epsilon$ }\\
						&\text{and $|m - n| \le \delta$)}\\
			max
			\begin{cases}
				LCSS_{\delta, \epsilon}(Head(T_1), T_2)\\
				LCSS_{\delta, \epsilon}(T_1, Head(T_2))
			\end{cases} &\text{otherwise}
		\end{cases}
\end{equation}

Как видно из приведенной формулы, вычисление LCSS зависит от двух постоянных параметров: $\delta$ (расположение точек \cite{online:r_lcss}) и $\epsilon$ (расстояние между точками \cite{online:r_lcss} или соответствующее пороговое значение для сравнения пространственной близости точек \cite{article:tr_sim_meas}):
 
\begin{itemize}
	\setlength\itemsep{-0.5em}
	\item параметр $\delta$ определяет максимальную удаленность в отношении времени между двумя точками траектории, в пределах которой мы можем искать соответствие данной точки траектории другой. Также может быть определено как значение, представляющее максимальную разность индексов между двумя входными траекториями, разрешенными при расчете \cite{online:r_lcss}.
	\item константа $\epsilon$ определяет минимальную границу пространственной близости при поиске совпадений. Согласно \cite{online:r_lcss}, это число с плавающей запятой, которое представляет собой максимально допустимое расстояние между точками траектории в каждом измерении, чтобы считать их эквивалентными: разница между $X$- и $Y$-координатами меньше, чем значение $\epsilon$ означает, что точки находятся относительно близко друг к другу и могут рассматриваться как эквивалентные. В этом случае расстояние LCSS увеличивается на 1.
\end{itemize}

Параметры $\delta$ и $\epsilon$ существенно влияют на результаты, поэтому задача выбора оптимальных значений для них является очень важной и сложной \cite{inproceedings:7_related_work}\cite{inproceedings:28_lcss_dsmt}. Функция $Head(T)$ определена так, чтобы возвращать первые $M - 1$ точки из траектории $T$, представляющие траекторию с удаленной последней точкой траектории. Согласно реализации, приведенной в \cite{online:r_lcss}, вычисление LCSS, основанное на подходе динамического программирования, имеет сложность $O((m + k)\delta)$. Однако алгоритм требует предопределенных постоянных значений параметров $\delta$ и $\varepsilon$ в качестве входных данных для метода. Кроме того, из-за рекурсивного способа вычислений LCSS имеет высокую вычислительную стоимость при работе с траекториями большой длины \cite{inproceedings:comp_sim_meas_trcl}.

\subsubsection{Выводы}

Метрика расстояния LCSS является наиболее подходящей в этой работе, поскольку она позволяет исходным траекториям содержать шум и аномалии, иметь различную длину, скорость объектов и частоту дискретизации (локальные временные сдвиги в траекториях) \cite{inproceedings:7_related_work}. Кроме того, среди вышеупомянутых методов расстояние LCSS является наиболее надежным подходом против помех.

\section{Выводы}

\subsubsection{Родственные методы}

Вышеупомянутая цель была исследована и решена в многочисленных работах с использованием различных методов. Поскольку на самом деле нормальные события являются более частыми и доминируют в данных, а ненормальные события редки и их трудно описать явно, многие подходы основаны на неконтролируемой кластеризации траекторий. Для этой дипломной работы в качестве основы был выбран подход, предложенный авторами Ghrab, Fendri, Hammami в \cite{inproceedings:7_related_work}. Он направлен на выявление отклонений с помощью кластеризации траекторий.

Предложенный подход можно описать как двухэтапный подход с автономной оффлайн кластеризацией для выявления частых траекторий и онлайн классификацией входной траектории для обозначения ее как нормальной или аномальной.

Кластеризация выполняется неконтролируемым образом с использованием алгоритма агломеративной иерархической кластеризации, работающего на матрице расстояний между траекториями. Для выполнения кластеризации расстояние LCSS используется в качестве меры сходства траекторий. Формулы и описание расстояния LCSS приведены в предыдущем разделе (\ref{eq:dlcss}-\ref{eq:lcss}).

\subsubsection{Преимущества}

Одним из преимуществ предлагаемого способа является то, что выбранная мера подобия не требует, чтобы траектории были одинаковой длины, так что можно избежать предварительной обработки траекторий, что само по себе является процессом высокой сложности. Более того, тренировочные данные могут содержать как нормальные, так и аномальные траектории: алгоритм будет выделять как нормальные, так и аномальные кластеры. Кластеры с высокой плотностю объектов будут представлять классы нормальных траекторий, разреженные кластеры - классы аномальных траекторий.

\subsubsection{Недостатки}

Однако недостатком предлагаемого способа является то, что расстояние LCSS не учитывает такие проблемы данных видеонаблюдения, как перспектива и положение движущегося объекта относительно видеокамеры.

\subsubsection{Поставленные задачи}

Таким образом, эта дипломная работа будет направлена на изучение возможности повышения точности результатов путем использования адаптивных параметров $\delta$ и $\varepsilon$, которые используются для расчета LCSS расстояния, зависящих от перспективы и расстояния от камеры. Это включает выполнение следующих задач:

\begin{itemize}
	\setlength\itemsep{-0.5em}
	\item изучение наличия и природы функциональной зависимости, возможно существующей между параметрами $\delta$ и $\varepsilon$ и расстоянием от камеры,
	\item протестировать результаты работы преложенного подхода на различных входных значениях параметров.
\end{itemize}